# modules/analyze.py
"""
åŠŸèƒ½ï¼š
1. ä½¿ç”¨ GPT å°è½‰éŒ„æ–‡å­—é€²è¡Œæ‘˜è¦ / å¤§ç¶± / å¾…è¾¦äº‹é …åˆ†æ
2. æä¾› run_analysis(text, preview) çµ¦ batch_job.py å‘¼å«
3. æ”¯æ´ preview æ¨¡å¼ï¼ˆåªåˆ†æå‰ 500 å­—ï¼‰
4. å¯ç›´æ¥åŸ·è¡Œï¼špython -m modules.analyze --preview
"""

import os
import sys
import json
from dotenv import load_dotenv
from openai import OpenAI
from docx import Document

# è¼‰å…¥ OpenAI é‡‘é‘°
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def ai_analyze(text: str) -> str:
    """å‘¼å« GPT é€²è¡Œåˆ†æï¼Œå›å‚³ JSON å­—ä¸²"""
    prompt = f"""
ä½ æ˜¯ä¸€å€‹æœƒè­°ç´€éŒ„åˆ†æåŠ©æ‰‹ã€‚è«‹ä¾æ“šä»¥ä¸‹é€å­—ç¨¿ï¼Œè¼¸å‡º JSON æ ¼å¼ï¼ŒåŒ…å«ï¼š
- "summary": æœƒè­°æ‘˜è¦ï¼ˆ3~5 å¥è©±ï¼‰
- "outline": ä¸»è¦è­°é¡Œæ¸…å–®ï¼ˆlistï¼Œæ¯å€‹å…ƒç´ æ˜¯ä¸€å€‹è­°é¡Œï¼‰
- "todos": å¾…è¾¦äº‹é …æ¸…å–®ï¼ˆlistï¼Œæ¯å€‹å…ƒç´ æ˜¯ä¸€å€‹å¾…è¾¦äº‹é …ï¼‰

é€å­—ç¨¿å¦‚ä¸‹ï¼š
{text}
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"},
        )
        return response.choices[0].message.content or ""
    except Exception as e:
        print(f"âŒ OpenAI åˆ†æéŒ¯èª¤ï¼š{e}")
        return "{}"  # å›å‚³ç©º JSON å­—ä¸²é˜²æ­¢ä¸­æ–·

def parse_sections(ai_output: str):
    """è§£æ JSONï¼ŒæŠ½å‡ºæ‘˜è¦ã€å¤§ç¶±ã€å¾…è¾¦"""
    try:
        data = json.loads(ai_output)
    except json.JSONDecodeError:
        data = {}
    summary = data.get("summary", "")
    outline = data.get("outline", [])
    todos = data.get("todos", [])
    return summary, outline, todos

# âœ… æä¾›ä¸»æµç¨‹ batch_job.py å‘¼å«
def run_analysis(text: str, preview: bool = False):
    """ä¸»å‡½å¼ï¼Œè¼¸å…¥æ–‡å­—å¾Œå›å‚³ï¼šæ‘˜è¦ã€å¤§ç¶±ã€å¾…è¾¦æ¸…å–®"""
    if not text:
        raise ValueError("ç„¡æ•ˆæ–‡å­—å…§å®¹")

    clipped = text[:500] if preview else text
    ai_output = ai_analyze(clipped)

    if not ai_output:
        ai_output = "{}"

    return parse_sections(ai_output)

# ğŸ”§ CLI æ¨¡å¼ç”¨çš„å‡½å¼ï¼ˆéå¿…è¦ï¼‰
def save_docx(path: str, summary: str, outline: list, todos: list):
    doc = Document()
    doc.add_heading("æœƒè­°æ‘˜è¦å ±å‘Š", level=0)

    doc.add_heading("æ‘˜è¦", level=1)
    doc.add_paragraph(summary if summary else "ï¼ˆç„¡å…§å®¹ï¼‰")

    doc.add_heading("å¤§ç¶±", level=1)
    for item in outline or ["ï¼ˆç„¡å…§å®¹ï¼‰"]:
        doc.add_paragraph(item, style="List Bullet")

    doc.add_heading("å¾…è¾¦äº‹é …", level=1)
    for item in todos or ["ï¼ˆç„¡å…§å®¹ï¼‰"]:
        doc.add_paragraph(item, style="List Number")

    doc.save(path)

def main():
    # CLI æ¨¡å¼æ¸¬è©¦ç”¨
    input_path = "output/final/transcript_revised.txt"
    preview_mode = "--preview" in sys.argv

    if not os.path.exists(input_path):
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æª”ï¼š{input_path}")
        return

    with open(input_path, "r", encoding="utf-8") as f:
        text = f.read()

    print(f"ğŸ¤– é–‹å§‹åˆ†æï¼ˆpreview={preview_mode}ï¼‰")
    summary, outline, todos = run_analysis(text, preview=preview_mode)

    # è¼¸å‡ºçµæœ
    result_txt = "ã€æ‘˜è¦ã€‘\n" + summary + "\n\nã€å¤§ç¶±ã€‘\n" + "\n".join(outline) + "\n\nã€å¾…è¾¦äº‹é …ã€‘\n" + "\n".join(todos)
    os.makedirs("output/final", exist_ok=True)

    with open("output/final/meeting_summary.txt", "w", encoding="utf-8") as f:
        f.write(result_txt)

    with open("output/final/meeting_summary.json", "w", encoding="utf-8") as f:
        json.dump({"summary": summary, "outline": outline, "todos": todos}, f, ensure_ascii=False, indent=2)

    save_docx("output/final/meeting_summary.docx", summary, outline, todos)

    print("âœ… å·²è¼¸å‡ºåˆ†æçµæœè‡³ output/final/")

if __name__ == "__main__":
    main()
